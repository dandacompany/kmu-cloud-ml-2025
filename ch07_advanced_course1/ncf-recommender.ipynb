{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Collaborative Filtering Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/dante/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# 데이터 처리 및 분석\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', None)\n",
    "import numpy as np\n",
    "\n",
    "# 머신러닝\n",
    "import tensorflow as tf\n",
    "\n",
    "# AWS 관련\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.utils import name_from_base\n",
    "import boto3\n",
    "import awswrangler as wr\n",
    "\n",
    "# 시각화\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# 기타 유틸리티\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import kaggle\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('script', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/ncf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/ncf.py\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class DataLoader:\n",
    "    @staticmethod\n",
    "    def load_training_data(base_dir):\n",
    "        \"\"\"훈련 데이터를 로드하고 분할합니다.\"\"\"\n",
    "        # 'train.npy' 파일에서 훈련 데이터를 로드합니다.\n",
    "        df_train = np.load(os.path.join(base_dir, 'train.npy'))\n",
    "        # 파일 목록을 출력합니다.\n",
    "        print(\"훈련 데이터 디렉토리 내용:\")\n",
    "        for file in os.listdir(base_dir):\n",
    "            print(f\"- {file}\")\n",
    "        # 데이터를 사용자, 아이템, 라벨로 분할합니다.\n",
    "        print(df_train.shape)\n",
    "        return np.split(np.transpose(df_train).flatten(), 3)\n",
    "\n",
    "    @staticmethod\n",
    "    def batch_generator(user_data, item_data, labels, batch_size, n_batch, shuffle, user_dim, item_dim):\n",
    "        \"\"\"훈련 및 테스트를 위한 배치를 생성합니다.\"\"\"\n",
    "        counter = 0\n",
    "        training_index = np.arange(user_data.shape[0])\n",
    "\n",
    "        if shuffle:\n",
    "            # 학습 데이터를 무작위로 섞습니다.\n",
    "            np.random.shuffle(training_index)\n",
    "\n",
    "        while True:\n",
    "            # 현재 배치의 인덱스를 선택합니다.\n",
    "            batch_index = training_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "            # 사용자와 아이템 데이터를 원-핫 인코딩합니다.\n",
    "            user_batch = tf.one_hot(user_data[batch_index], depth=user_dim)\n",
    "            item_batch = tf.one_hot(item_data[batch_index], depth=item_dim)\n",
    "            y_batch = labels[batch_index]\n",
    "            counter += 1\n",
    "            # 배치 데이터를 생성합니다.\n",
    "            yield [user_batch, item_batch], y_batch\n",
    "\n",
    "            if counter == n_batch:\n",
    "                if shuffle:\n",
    "                    # 모든 배치를 순회한 후 데이터를 다시 섞습니다.\n",
    "                    np.random.shuffle(training_index)\n",
    "                counter = 0\n",
    "\n",
    "class NeuralCollaborativeFiltering:\n",
    "    def __init__(self, user_dim, item_dim, dropout_rate=0.25):\n",
    "        \"\"\"Neural Collaborative Filtering 모델 초기화\"\"\"\n",
    "        self.user_dim = user_dim\n",
    "        self.item_dim = item_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Neural Collaborative Filtering 모델을 구축합니다.\"\"\"\n",
    "        # 사용자와 아이템 입력 레이어를 정의합니다.\n",
    "        user_input = tf.keras.Input(shape=(self.user_dim,))\n",
    "        item_input = tf.keras.Input(shape=(self.item_dim,))\n",
    "\n",
    "        # 사용자와 아이템의 임베딩을 생성합니다.\n",
    "        user_gmf_emb, user_mlp_emb = self._create_user_embeddings(user_input)\n",
    "        item_gmf_emb, item_mlp_emb = self._create_item_embeddings(item_input)\n",
    "\n",
    "        # GMF(General Matrix Factorization)와 MLP(Multi-Layer Perceptron) 출력을 계산합니다.\n",
    "        gmf_output = self._general_matrix_factorization(user_gmf_emb, item_gmf_emb)\n",
    "        mlp_output = self._multi_layer_perceptron(user_mlp_emb, item_mlp_emb)\n",
    "\n",
    "        # 최종 출력을 계산합니다.\n",
    "        output = self._neural_cf(gmf_output, mlp_output)\n",
    "\n",
    "        # 모델을 생성하고 반환합니다.\n",
    "        return tf.keras.Model(inputs=[user_input, item_input], outputs=output)\n",
    "\n",
    "    def _create_user_embeddings(self, inputs):\n",
    "        \"\"\"GMF와 MLP를 위한 사용자 임베딩을 생성합니다.\"\"\"\n",
    "        # GMF를 위한 사용자 임베딩\n",
    "        gmf_emb = tf.keras.layers.Dense(32, activation='relu')(inputs)\n",
    "        # MLP를 위한 사용자 임베딩\n",
    "        mlp_emb = tf.keras.layers.Dense(32, activation='relu')(inputs)\n",
    "        return gmf_emb, mlp_emb\n",
    "\n",
    "    def _create_item_embeddings(self, inputs):\n",
    "        \"\"\"GMF와 MLP를 위한 아이템 임베딩을 생성합니다.\"\"\"\n",
    "        # GMF를 위한 아이템 임베딩\n",
    "        gmf_emb = tf.keras.layers.Dense(32, activation='relu')(inputs)\n",
    "        # MLP를 위한 아이템 임베딩\n",
    "        mlp_emb = tf.keras.layers.Dense(32, activation='relu')(inputs)\n",
    "        return gmf_emb, mlp_emb\n",
    "\n",
    "    def _general_matrix_factorization(self, user_emb, item_emb):\n",
    "        \"\"\"General Matrix Factorization 브랜치를 구현합니다.\"\"\"\n",
    "        # 사용자와 아이템 임베딩의 요소별 곱을 계산합니다.\n",
    "        return tf.keras.layers.Multiply()([user_emb, item_emb])\n",
    "\n",
    "    def _multi_layer_perceptron(self, user_emb, item_emb):\n",
    "        \"\"\"Multi-Layer Perceptron 브랜치를 구현합니다.\"\"\"\n",
    "        # 사용자와 아이템 임베딩을 연결합니다.\n",
    "        concat_layer = tf.keras.layers.Concatenate()([user_emb, item_emb])\n",
    "        # 드롭아웃 레이어를 적용하여 과적합을 방지합니다.\n",
    "        dropout = tf.keras.layers.Dropout(self.dropout_rate)(concat_layer)\n",
    "\n",
    "        # 여러 개의 완전 연결 레이어를 추가합니다.\n",
    "        dense1 = tf.keras.layers.Dense(64, activation='relu')(dropout)\n",
    "        dense2 = tf.keras.layers.Dense(32, activation='relu')(dense1)\n",
    "        dense3 = tf.keras.layers.Dense(16, activation='relu')(dense2)\n",
    "        dense4 = tf.keras.layers.Dense(8, activation='relu')(dense3)\n",
    "\n",
    "        return dense4\n",
    "\n",
    "    def _neural_cf(self, gmf, mlp):\n",
    "        \"\"\"GMF와 MLP 출력을 결합합니다.\"\"\"\n",
    "        # GMF와 MLP 출력을 연결합니다.\n",
    "        concat_layer = tf.keras.layers.Concatenate()([gmf, mlp])\n",
    "        # 최종 출력 레이어(시그모이드 활성화 함수를 사용한 이진 분류)\n",
    "        return tf.keras.layers.Dense(1, activation='sigmoid')(concat_layer)\n",
    "\n",
    "def train_model(x_train, y_train, n_user, n_item, num_epoch, batch_size):\n",
    "    \"\"\"Neural Collaborative Filtering 모델을 훈련시킵니다.\"\"\"\n",
    "    # 전체 배치 수를 계산합니다.\n",
    "    num_batch = np.ceil(x_train[0].shape[0] / batch_size)\n",
    "\n",
    "    # 모델 인스턴스를 생성합니다.\n",
    "    ncf = NeuralCollaborativeFiltering(n_user, n_item)\n",
    "    model = ncf.build_model()\n",
    "\n",
    "    # 옵티마이저를 설정합니다.\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    # 모델을 컴파일합니다.\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 데이터 로더 인스턴스를 생성합니다.\n",
    "    data_loader = DataLoader()\n",
    "    # 모델을 훈련시킵니다.\n",
    "    model.fit(\n",
    "        data_loader.batch_generator(\n",
    "            x_train[0], x_train[1], y_train,\n",
    "            batch_size=batch_size, n_batch=num_batch,\n",
    "            shuffle=True, user_dim=n_user, item_dim=n_item),\n",
    "        epochs=num_epoch,\n",
    "        steps_per_epoch=num_batch,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"명령줄 인자를 파싱합니다.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Neural Collaborative Filtering 모델 훈련\")\n",
    "    parser.add_argument('--model_dir', type=str, help=\"모델 출력 디렉토리\")\n",
    "    parser.add_argument('--sm-model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'), help=\"SageMaker 모델 출력 디렉토리\")\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAINING'), help=\"훈련 데이터 디렉토리\")\n",
    "    parser.add_argument('--hosts', type=json.loads, default=json.loads(os.environ.get('SM_HOSTS')), help=\"분산 훈련을 위한 호스트\")\n",
    "    parser.add_argument('--current-host', type=str, default=os.environ.get('SM_CURRENT_HOST'), help=\"분산 훈련에서 현재 호스트\")\n",
    "    parser.add_argument('--epochs', type=int, default=3, help=\"훈련 에포크 수\")\n",
    "    parser.add_argument('--batch_size', type=int, default=256, help=\"훈련 배치 크기\")\n",
    "    parser.add_argument('--n_user', type=int, required=True, help=\"사용자 수\")\n",
    "    parser.add_argument('--n_item', type=int, required=True, help=\"아이템 수\")\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 명령줄 인자를 파싱합니다.\n",
    "    args = parse_args()\n",
    "\n",
    "    # 훈련 데이터를 로드합니다.\n",
    "    data_loader = DataLoader()\n",
    "    user_train, item_train, train_labels = data_loader.load_training_data(args.train)\n",
    "\n",
    "    # 모델을 훈련시킵니다.\n",
    "    ncf_model = train_model(\n",
    "        x_train=[user_train, item_train],\n",
    "        y_train=train_labels,\n",
    "        n_user=args.n_user,\n",
    "        n_item=args.n_item,\n",
    "        num_epoch=args.epochs,\n",
    "        batch_size=args.batch_size\n",
    "    )\n",
    "\n",
    "    # 모델을 저장합니다.\n",
    "    if args.current_host == args.hosts[0]:\n",
    "        ncf_model.save(os.path.join(args.sm_model_dir, '000000001'), 'neural_collaborative_filtering.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker 세션 및 역할 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_session = boto3.Session(profile_name='awstutor')\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto3_session)\n",
    "role = os.environ.get('SAGEMAKER_EXECUTION_ROLE_ARN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database\n"
     ]
    }
   ],
   "source": [
    "kaggle_dataset_name = 'CooperUnion/anime-recommendations-database'\n",
    "kaggle.api.authenticate()\n",
    "kaggle.api.dataset_download_files(kaggle_dataset_name, path='./dataset/anime', unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 로드 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime = pd.read_csv('./dataset/anime/anime.csv')\n",
    "rating = pd.read_csv('./dataset/anime/rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12294, 7), (7813737, 3))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime.shape, rating.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>name</th>\n",
       "      <th>genre</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>rating</th>\n",
       "      <th>members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32281</td>\n",
       "      <td>Kimi no Na wa.</td>\n",
       "      <td>Drama, Romance, School, Supernatural</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>9.37</td>\n",
       "      <td>200630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5114</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n",
       "      <td>TV</td>\n",
       "      <td>64</td>\n",
       "      <td>9.26</td>\n",
       "      <td>793665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28977</td>\n",
       "      <td>Gintama°</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>TV</td>\n",
       "      <td>51</td>\n",
       "      <td>9.25</td>\n",
       "      <td>114262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9253</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>Sci-Fi, Thriller</td>\n",
       "      <td>TV</td>\n",
       "      <td>24</td>\n",
       "      <td>9.17</td>\n",
       "      <td>673572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9969</td>\n",
       "      <td>Gintama&amp;#039;</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>TV</td>\n",
       "      <td>51</td>\n",
       "      <td>9.16</td>\n",
       "      <td>151266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                              name  \\\n",
       "0     32281                    Kimi no Na wa.   \n",
       "1      5114  Fullmetal Alchemist: Brotherhood   \n",
       "2     28977                          Gintama°   \n",
       "3      9253                       Steins;Gate   \n",
       "4      9969                     Gintama&#039;   \n",
       "\n",
       "                                               genre   type episodes  rating  \\\n",
       "0               Drama, Romance, School, Supernatural  Movie        1    9.37   \n",
       "1  Action, Adventure, Drama, Fantasy, Magic, Mili...     TV       64    9.26   \n",
       "2  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.25   \n",
       "3                                   Sci-Fi, Thriller     TV       24    9.17   \n",
       "4  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.16   \n",
       "\n",
       "   members  \n",
       "0   200630  \n",
       "1   793665  \n",
       "2   114262  \n",
       "3   673572  \n",
       "4   151266  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>226</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  anime_id  rating\n",
       "0        1        20      -1\n",
       "1        1        24      -1\n",
       "2        1        79      -1\n",
       "3        1       226      -1\n",
       "4        1       241      -1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       " 8     1646019\n",
       "-1     1476496\n",
       " 7     1375287\n",
       " 9     1254096\n",
       " 10     955715\n",
       " 6      637775\n",
       " 5      282806\n",
       " 4      104291\n",
       " 3       41453\n",
       " 2       23150\n",
       " 1       16649\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12294 entries, 0 to 12293\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   anime_id  12294 non-null  int64  \n",
      " 1   name      12294 non-null  object \n",
      " 2   genre     12232 non-null  object \n",
      " 3   type      12269 non-null  object \n",
      " 4   episodes  12294 non-null  object \n",
      " 5   rating    12064 non-null  float64\n",
      " 6   members   12294 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 672.5+ KB\n"
     ]
    }
   ],
   "source": [
    "anime.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 데이터 수: 7813730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7813730, 3)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 장르 정보가 없는 애니메이션에 대해 'No Genre' 값을 할당\n",
    "anime.loc[anime.genre.isna(), 'genre'] = 'No Genre'\n",
    "\n",
    "# 1. 중복된 데이터의 평점 평균 계산\n",
    "rating_mean = rating.groupby(['user_id', 'anime_id'])['rating'].mean().reset_index()\n",
    "\n",
    "# 2. 원본 데이터에서 중복 제거 (첫 번째 항목 유지)\n",
    "rating_deduped = rating.drop_duplicates(subset=['user_id', 'anime_id'], keep='first')\n",
    "\n",
    "# 3. 중복 제거된 데이터의 평점을 평균 평점으로 업데이트\n",
    "rating_deduped = rating_deduped.merge(rating_mean, on=['user_id', 'anime_id'], suffixes=('_old', ''))\n",
    "\n",
    "# 4. 기존 'rating_old' 열 삭제\n",
    "df_rating = rating_deduped.drop(columns=['rating_old'])\n",
    "\n",
    "print(f\"중복 제거 후 데이터 수: {len(df_rating)}\")\n",
    "\n",
    "df_rating.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자별 애니메이션 평가 횟수가 100회 이상인 사용자와\n",
    "# 애니메이션별 평가 횟수가 100회 이상인 애니메이션만 선택\n",
    "\n",
    "# 1. 사용자별 애니메이션 평가 횟수가 100회 이상인 사용자 선택\n",
    "df_rating_tmp = df_rating.merge(\n",
    "    (df_rating.groupby('user_id').count().anime_id > 100).reset_index(), \n",
    "        on='user_id', how='inner', suffixes=(None, '_tmp')\n",
    ")\n",
    "\n",
    "# 애니메이션별 평가 횟수가 100회 이상인 애니메이션 선택\n",
    "df_rating_tmp = df_rating_tmp.set_index('anime_id').merge(\n",
    "    (df_rating.groupby('anime_id').count().user_id > 100).reset_index(),\n",
    "        on='anime_id', how='inner', suffixes=(None, '_tmp')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5963423, 3)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용자와 애니메이션 모두 100회 이상 평가된 데이터만 선택\n",
    "df_rating_adj = df_rating_tmp[df_rating_tmp.apply(lambda x: x.user_id_tmp and x.anime_id_tmp, axis=1)].drop(columns=['user_id_tmp', 'anime_id_tmp'])\n",
    "\n",
    "# 조정된 데이터셋의 크기 확인\n",
    "df_rating_adj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 셔플 및 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임을 무작위로 섞습니다.\n",
    "# frac=1은 전체 데이터를 사용한다는 의미입니다.\n",
    "suffled_ratings_df = df_rating_adj.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 사용자별로 처음 30개의 데이터를 테스트 세트로 분리\n",
    "df_test = suffled_ratings_df.groupby(['user_id']).apply(lambda x: x.iloc[:30]).reset_index(drop=True)\n",
    "\n",
    "# 각 사용자별로 30번째 이후의 데이터를 훈련 세트로 분리\n",
    "df_train = suffled_ratings_df.groupby(['user_id']).apply(lambda x: x.iloc[30:]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 크기: (5223138, 3)\n",
      "테스트 데이터 크기: (740285, 3)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 중복 또는 손실 여부 확인을 위한 무결성 검사\n",
    "assert suffled_ratings_df.shape[0] == df_train.shape[0] + df_test.shape[0]\n",
    "\n",
    "print(\"훈련 데이터 크기:\", df_train.shape)\n",
    "print(\"테스트 데이터 크기:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 분할 및 저장 완료\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터를 CSV 파일로 저장\n",
    "df_train.to_csv('./dataset/anime/user_anime_train.csv', index=False)\n",
    "df_test.to_csv('./dataset/anime/user_anime_test.csv', index=False)\n",
    "\n",
    "print(\"데이터 분할 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고유한 아이템 및 사용자 수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_items = suffled_ratings_df.anime_id.unique()\n",
    "unique_users = suffled_ratings_df.user_id.unique()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "부정적 샘플 생성 및 병합\n",
    "```\n",
    "사용자가 어떤 작품에 대해 긍정적으로 평가했다면, \n",
    "그 데이터만으로는 모델 학습에 한계가 있습니다. \n",
    "그래서 각 사용자별로 아직 보지 않은 작품 중에서 임의로 몇 개를 골라 부정적인 샘플로 추가합니다. \n",
    "이렇게 하면 모델이 더 균형 잡힌 학습을 할 수 있죠.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_samples(user_ids, anime_ids, items, n_neg):\n",
    "    \"\"\"이 함수는 모든 긍정적 레이블에 대해 n_neg개의 부정적 레이블을 생성합니다.\n",
    "    \n",
    "    @param user_ids: 사용자 ID 목록\n",
    "    @param anime_ids: 애니메이션 ID 목록\n",
    "    @param items: 고유한 애니메이션 ID 목록\n",
    "    @param n_neg: 샘플링할 부정적 레이블의 수\n",
    "    \n",
    "    @return df_neg: 부정적 샘플 데이터프레임\n",
    "    \n",
    "    \"\"\"\n",
    "    from tqdm import tqdm\n",
    "    neg = []\n",
    "    ui_pairs = zip(user_ids, anime_ids)\n",
    "    records = set(ui_pairs)\n",
    "    \n",
    "    # 모든 긍정적 레이블 케이스에 대해\n",
    "    for (u, i) in tqdm(records):\n",
    "        # n_neg개의 부정적 레이블 생성\n",
    "        for _ in range(n_neg):\n",
    "            # 무작위로 샘플링된 애니메이션이 해당 사용자에게 존재하는 경우\n",
    "            j = np.random.choice(items)\n",
    "            while (u, j) in records:\n",
    "                # 재샘플링\n",
    "                j = np.random.choice(items)\n",
    "            neg.append([u, j, 0])\n",
    "    # 나중에 연결을 위해 pandas 데이터프레임으로 변환\n",
    "    df_neg = pd.DataFrame(neg, columns=['user_id', 'anime_id', 'rating'])\n",
    "    \n",
    "    return df_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5223138/5223138 [00:35<00:00, 148892.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# 부정적 샘플 생성\n",
    "neg_train = generate_negative_samples(\n",
    "    user_ids=df_train.user_id.values, \n",
    "    anime_ids=df_train.anime_id.values,\n",
    "    items=unique_items,\n",
    "    n_neg=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58046</td>\n",
       "      <td>1556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35486</td>\n",
       "      <td>1469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52481</td>\n",
       "      <td>25939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39522</td>\n",
       "      <td>1168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61254</td>\n",
       "      <td>6162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9192</td>\n",
       "      <td>8792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57892</td>\n",
       "      <td>1744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33085</td>\n",
       "      <td>6867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31200</td>\n",
       "      <td>529</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52366</td>\n",
       "      <td>8728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  anime_id  rating\n",
       "0    58046      1556       0\n",
       "1    35486      1469       0\n",
       "2    52481     25939       0\n",
       "3    39522      1168       0\n",
       "4    61254      6162       0\n",
       "5     9192      8792       0\n",
       "6    57892      1744       0\n",
       "7    33085      6867       0\n",
       "8    31200       529       0\n",
       "9    52366      8728       0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created 5,223,138 negative samples\n"
     ]
    }
   ],
   "source": [
    "print(f'created {neg_train.shape[0]:,} negative samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터에서 'user_id'와 'anime_id' 열만 선택하고 'rating' 열을 1로 설정\n",
    "df_train = df_train[['user_id', 'anime_id']].assign(rating=1)\n",
    "df_test = df_test[['user_id', 'anime_id']].assign(rating=1)\n",
    "\n",
    "# 훈련 데이터에 부정적 샘플 추가\n",
    "df_train = pd.concat([df_train, neg_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고유 사용자 수 24677\n",
      "고유 아이템 수 4575\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(unique_users, open('./dataset/anime/n_user.pkl', 'wb'))\n",
    "pickle.dump(unique_items, open('./dataset/anime/n_item.pkl', 'wb'))\n",
    "print(\"고유 사용자 수\", len(unique_users))\n",
    "print(\"고유 아이템 수\", len(unique_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨테이너 모델 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3 데이터 경로 설정 및 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'dante-sagemaker'\n",
    "project_name = 'ncf-recommender'\n",
    "train_path = os.path.join(f's3://{bucket_name}/{project_name}/train/')\n",
    "script_path = os.path.join(f's3://{bucket_name}/{project_name}/script/')\n",
    "output_path = os.path.join(f's3://{bucket_name}/{project_name}/output/') \n",
    "checkpoint_path = os.path.join(f's3://{bucket_name}/{project_name}/checkpoints/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 15:39:06,621 WARNING Connection pool is full, discarding connection: dante-sagemaker.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dante-sagemaker.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "2024-08-14 15:39:06,708 WARNING Connection pool is full, discarding connection: dante-sagemaker.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dante-sagemaker.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로컬에 저장\n",
    "location = 'dataset/anime'\n",
    "local_train_path = os.path.join(location, 'train.npy')\n",
    "local_test_path = os.path.join(location, 'test.npy')\n",
    "\n",
    "# 훈련 및 테스트 데이터를 NumPy 배열로 저장\n",
    "np.save(local_train_path, df_train.values)\n",
    "np.save(local_test_path, df_test.values)\n",
    "\n",
    "# S3 버킷에 파일 업로드\n",
    "# NCF 모델 스크립트 업로드\n",
    "wr.s3.upload(local_file=\"script/ncf.py\", path=os.path.join(script_path, 'ncf.py'), boto3_session=boto3_session)\n",
    "# 훈련 데이터 업로드\n",
    "wr.s3.upload(local_file=local_train_path, path=os.path.join(train_path, 'train.npy'), boto3_session=boto3_session)\n",
    "# 테스트 데이터 업로드\n",
    "wr.s3.upload(local_file=local_test_path, path=os.path.join(train_path, 'test.npy'), boto3_session=boto3_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 컨테이너 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributions has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "ncf_estimator = TensorFlow(\n",
    "    entry_point='script/ncf.py',\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    output_path=output_path,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c5.2xlarge',\n",
    "    framework_version='2.1.0',\n",
    "    py_version='py3',\n",
    "    distributions={\n",
    "        'parameter_server': {'enabled': True}\n",
    "    },\n",
    "    hyperparameters= {\n",
    "        'epochs': 1,\n",
    "        'batch_size': 512, \n",
    "        'n_user': len(unique_users), \n",
    "        'n_item': len(unique_items)\n",
    "    },\n",
    "    use_spot_instances=True,\n",
    "    max_wait=3600,\n",
    "    max_run=3600,\n",
    "    checkpoint_s3_uri=checkpoint_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: ncf-recommender-training-2024-08-14-08-03-00-881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-14 08:03:01 Starting - Starting the training job...\n",
      "2024-08-14 08:03:17 Starting - Preparing the instances for training...\n",
      "2024-08-14 08:03:57 Downloading - Downloading the training image...\n",
      "2024-08-14 08:04:12 Training - Training image download completed. Training in progress.2024-08-14 08:04:14,508 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "2024-08-14 08:04:14,515 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-08-14 08:04:14,692 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-08-14 08:04:14,706 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-08-14 08:04:14,719 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-08-14 08:04:14,728 sagemaker-containers INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 512,\n",
      "        \"epochs\": 1,\n",
      "        \"model_dir\": \"s3://dante-sagemaker/ncf-recommender/output/ncf-recommender-training-2024-08-14-08-03-00-881/model\",\n",
      "        \"n_item\": 4575,\n",
      "        \"n_user\": 24677\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"ContentType\": \"application/x-npy\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"ncf-recommender-training-2024-08-14-08-03-00-881\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://dante-sagemaker/ncf-recommender-training-2024-08-14-08-03-00-881/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"ncf\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"ncf.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch_size\":512,\"epochs\":1,\"model_dir\":\"s3://dante-sagemaker/ncf-recommender/output/ncf-recommender-training-2024-08-14-08-03-00-881/model\",\"n_item\":4575,\"n_user\":24677}\n",
      "SM_USER_ENTRY_POINT=ncf.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"training\":{\"ContentType\":\"application/x-npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"training\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_MODULE_NAME=ncf\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://dante-sagemaker/ncf-recommender-training-2024-08-14-08-03-00-881/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":512,\"epochs\":1,\"model_dir\":\"s3://dante-sagemaker/ncf-recommender/output/ncf-recommender-training-2024-08-14-08-03-00-881/model\",\"n_item\":4575,\"n_user\":24677},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"ContentType\":\"application/x-npy\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"ncf-recommender-training-2024-08-14-08-03-00-881\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://dante-sagemaker/ncf-recommender-training-2024-08-14-08-03-00-881/source/sourcedir.tar.gz\",\"module_name\":\"ncf\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"ncf.py\"}\n",
      "SM_USER_ARGS=[\"--batch_size\",\"512\",\"--epochs\",\"1\",\"--model_dir\",\"s3://dante-sagemaker/ncf-recommender/output/ncf-recommender-training-2024-08-14-08-03-00-881/model\",\"--n_item\",\"4575\",\"--n_user\",\"24677\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "SM_HP_BATCH_SIZE=512\n",
      "SM_HP_EPOCHS=1\n",
      "SM_HP_MODEL_DIR=s3://dante-sagemaker/ncf-recommender/output/ncf-recommender-training-2024-08-14-08-03-00-881/model\n",
      "SM_HP_N_ITEM=4575\n",
      "SM_HP_N_USER=24677\n",
      "PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "Invoking script with the following command:\n",
      "/usr/bin/python3 ncf.py --batch_size 512 --epochs 1 --model_dir s3://dante-sagemaker/ncf-recommender/output/ncf-recommender-training-2024-08-14-08-03-00-881/model --n_item 4575 --n_user 24677\n",
      "훈련 데이터 디렉토리 내용:\n",
      "- train.npy\n",
      "- test.npy\n",
      "(10446276, 3)\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 20403.0 steps\n",
      "20403/20403 - 640s - loss: 0.5998 - accuracy: 0.6390\n",
      "2024-08-14 08:14:57.200183: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "2024-08-14 08:14:57.572337: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /opt/ml/model/000000001/assets\n",
      "INFO:tensorflow:Assets written to: /opt/ml/model/000000001/assets\n",
      "2024-08-14 08:14:58,226 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\n",
      "2024-08-14 08:15:05 Uploading - Uploading generated training model\n",
      "2024-08-14 08:15:17 Completed - Training job completed\n",
      "Training seconds: 701\n",
      "Billable seconds: 203\n",
      "Managed Spot Training savings: 71.0%\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "training_job_name = name_from_base(f\"{project_name}-training\")\n",
    "\n",
    "ncf_estimator.fit(\n",
    "    inputs= {\n",
    "        'training': TrainingInput(s3_data=train_path, content_type='application/x-npy'),\n",
    "    },\n",
    "    job_name=training_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "엔드포인트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최근 완료된 훈련 작업 목록:\n",
      "작업 이름: ncf-recommender-training-2024-08-14-08-03-00-881\n",
      "생성 시간: 2024-08-14 17:03:01.211000+09:00\n",
      "완료 시간: 2024-08-14 17:15:17.547000+09:00\n",
      "상태: Completed\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ncf-recommender-training-2024-08-14-08-03-00-881']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 작업 목록 조회\n",
    "sagemaker_client = boto3_session.client('sagemaker')\n",
    "response = sagemaker_client.list_training_jobs(\n",
    "    StatusEquals='Completed',\n",
    "    SortBy='CreationTime',\n",
    "    SortOrder='Descending',\n",
    "    MaxResults=5\n",
    ")\n",
    "\n",
    "job_names = []\n",
    "\n",
    "print(\"최근 완료된 훈련 작업 목록:\")\n",
    "for job in response['TrainingJobSummaries']:\n",
    "    if job['TrainingJobName'].startswith(f'{project_name}-training'):\n",
    "        job_names.append(job['TrainingJobName'])\n",
    "        print(f\"작업 이름: {job['TrainingJobName']}\")\n",
    "        print(f\"생성 시간: {job['CreationTime']}\")\n",
    "        print(f\"완료 시간: {job['TrainingEndTime']}\")\n",
    "        print(f\"상태: {job['TrainingJobStatus']}\")\n",
    "        print(\"-\" * 50)\n",
    "job_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 아티팩트 위치: s3://dante-sagemaker/ncf-recommender/output/ncf-recommender-training-2024-08-14-08-03-00-881/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# 최근 완료된 훈련작업을 통한 모델 아티팩트 위치 얻기\n",
    "sagemaker_client = boto3_session.client('sagemaker')\n",
    "response = sagemaker_client.describe_training_job(TrainingJobName=job_names[0])\n",
    "model_artifacts = response['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "print(f\"모델 아티팩트 위치: {model_artifacts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "ncf_estimator = TensorFlowModel(\n",
    "    model_data=model_artifacts,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version='2.1.0',\n",
    "    entry_point='script/ncf.py',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.tensorflow.model:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating model with name: tensorflow-inference-2024-08-14-08-19-10-784\n",
      "INFO:sagemaker:Creating endpoint-config with name ncf-recommender-ncf-endpoint-2024-08-14-08-19-05-263\n",
      "INFO:sagemaker:Creating endpoint with name ncf-recommender-ncf-endpoint-2024-08-14-08-19-05-263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "endpoint_name = name_from_base(project_name + '-ncf-endpoint')\n",
    "\n",
    "ncf_estimator.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type=\"ml.m5.2xlarge\", \n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_user, n_item = 24677, 4575\n",
    "project_name = 'ncf-recommender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique users 24677\n",
      "number of unique items 4575\n"
     ]
    }
   ],
   "source": [
    "n_user, n_item = len(unique_users), len(unique_items)\n",
    "\n",
    "print(\"number of unique users\", n_user)\n",
    "print(\"number of unique items\", n_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000,), (50000,), (50000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터 로드\n",
    "df_test = np.load('dataset/anime/test.npy')\n",
    "# 원핫인코딩으로 인해 많은 메로리가 필요하므로, 5만행으로 데이터를 줄여 진행합니다.\n",
    "sub_df_test = df_test[:50000]\n",
    "user_test, item_test, y_test = np.split(np.transpose(sub_df_test).flatten(), 3)\n",
    "user_test.shape, item_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:31<00:00,  1.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 입력을 위해 테스트 데이터를 원-핫 인코딩\n",
    "batch_size = 1000  # 메모리 사용량을 줄이기 위해 배치 크기 설정\n",
    "\n",
    "test_user_data = []\n",
    "test_item_data = []\n",
    "\n",
    "for i in tqdm(range(0, len(user_test), batch_size)):\n",
    "    batch_user = user_test[i:i+batch_size]\n",
    "    batch_item = item_test[i:i+batch_size]\n",
    "    \n",
    "    user_batch = tf.one_hot(batch_user, depth=n_user).numpy()\n",
    "    item_batch = tf.one_hot(batch_item, depth=n_item).numpy()\n",
    "    \n",
    "    test_user_data.extend(user_batch.tolist())\n",
    "    test_item_data.extend(item_batch.tolist())\n",
    "\n",
    "# 메모리 정리\n",
    "del user_batch, item_batch\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "엔드포인트 실시간 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 존재하는 엔드포인트 목록:\n",
      "ncf-recommender-ncf-endpoint-2024-08-14-08-19-05-263\n"
     ]
    }
   ],
   "source": [
    "# 엔드포인트 목록 조회\n",
    "sagemaker_client = boto3_session.client('sagemaker')\n",
    "response = sagemaker_client.list_endpoints()\n",
    "endpoint_name = None\n",
    "# 엔드포인트 이름 출력\n",
    "print(\"현재 존재하는 엔드포인트 목록:\")\n",
    "for endpoint in response['Endpoints']:\n",
    "    if endpoint['EndpointName'].startswith(f'{project_name}-ncf-endpoint'):\n",
    "        endpoint_name = endpoint['EndpointName']\n",
    "        print(endpoint['EndpointName'])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# 배치 예측 수행\n",
    "runtime = boto3_session.client('runtime.sagemaker')\n",
    "batch_size = 100\n",
    "y_pred = []\n",
    "for idx in tqdm(range(0, len(test_user_data), batch_size)):\n",
    "    # 테스트 샘플을 TensorFlow Serving이 수용 가능한 형식으로 재구성\n",
    "    input_vals = {\n",
    "     \"instances\": [\n",
    "         {'input_1': u, 'input_2': i} \n",
    "         for (u, i) in zip(test_user_data[idx:idx+batch_size], test_item_data[idx:idx+batch_size])\n",
    "    ]}\n",
    "    # 엔드포인트 호출\n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        Body=json.dumps(input_vals)\n",
    "    )\n",
    "    # 응답 파싱\n",
    "    pred = json.loads(response['Body'].read().decode())\n",
    " \n",
    "    # 예측 결과 저장\n",
    "    y_pred.extend([i[0] for i in pred['predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 예측 데이터 5개\n",
      "--------------------------------------------------------------------------------\n",
      "[0.573741, 0.573741, 0.573741, 0.573741, 0.573741]\n",
      "\n",
      "\n",
      "2. 사용자-아이템 쌍 데이터프레임\n",
      "--------------------------------------------------------------------------------\n",
      "   사용자ID  애니메이션ID       선호도\n",
      "0      1    10578  0.573741\n",
      "1      1    16011  0.573741\n",
      "2      1     9330  0.573741\n",
      "3      1    10079  0.573741\n",
      "4      1    15451  0.573741\n",
      "\n",
      "\n",
      "3. 사용자별 상위 5개 추천 애니메이션 목록\n",
      "--------------------------------------------------------------------------------\n",
      "                                      0\n",
      "사용자ID                                  \n",
      "1            [356, 2787, 79, 24, 10578]\n",
      "5          [4214, 1887, 150, 4472, 918]\n",
      "7      [552, 4472, 31704, 15583, 18671]\n",
      "11           [44, 3652, 532, 1709, 104]\n",
      "\n",
      "\n",
      "4. 5명의 사용자에 대한 상세 추천 정보\n",
      "--------------------------------------------------------------------------------\n",
      "사용자 ID: 1\n",
      "    애니메이션ID       선호도\n",
      "24      356  0.938439\n",
      "13     2787  0.884002\n",
      "6        79  0.815785\n",
      "12       24  0.788223\n",
      "0     10578  0.573741\n",
      "\n",
      "사용자 ID: 5\n",
      "    애니메이션ID       선호도\n",
      "55     4214  0.954283\n",
      "49     1887  0.933758\n",
      "34      150  0.917900\n",
      "41     4472  0.853350\n",
      "35      918  0.812641\n",
      "\n",
      "사용자 ID: 7\n",
      "    애니메이션ID       선호도\n",
      "68      552  0.770155\n",
      "69     4472  0.691436\n",
      "60    31704  0.588950\n",
      "61    15583  0.588950\n",
      "62    18671  0.588950\n",
      "\n",
      "사용자 ID: 11\n",
      "    애니메이션ID       선호도\n",
      "91       44  0.912131\n",
      "96     3652  0.886870\n",
      "97      532  0.790907\n",
      "99     1709  0.729713\n",
      "93      104  0.709876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예측 확률을 선호도로 간주하여 상위 추천 애니메이션 확인\n",
    "print('1. 예측 데이터 5개')\n",
    "print('-'*80)\n",
    "print(y_pred[:5], end='\\n\\n\\n')\n",
    "\n",
    "# 사용자-아이템 쌍 데이터프레임 생성, 예측값은 확률 그대로 사용\n",
    "pred_df = pd.DataFrame({\n",
    "    '사용자ID': user_test,\n",
    "    '애니메이션ID': item_test,\n",
    "    '선호도': y_pred\n",
    "})\n",
    "\n",
    "print('2. 사용자-아이템 쌍 데이터프레임')\n",
    "print('-'*80)\n",
    "print(pred_df.head(), end='\\n\\n\\n')\n",
    "\n",
    "# 사용자별 상위 5개 추천 애니메이션 목록\n",
    "print('3. 사용자별 상위 5개 추천 애니메이션 목록')\n",
    "print('-'*80)\n",
    "top_recommendations = pred_df.groupby('사용자ID').apply(lambda x: x.nlargest(5, '선호도')['애니메이션ID'].tolist()).head()\n",
    "print(top_recommendations.to_frame(), end='\\n\\n\\n')\n",
    "\n",
    "# 5명의 사용자에 대한 상세 추천 정보 출력\n",
    "print('4. 5명의 사용자에 대한 상세 추천 정보')\n",
    "print('-'*80)\n",
    "for user_id in top_recommendations.index[:5]:\n",
    "    user_recs = pred_df[pred_df['사용자ID'] == user_id].nlargest(5, '선호도')\n",
    "    print(f\"사용자 ID: {user_id}\")\n",
    "    print(user_recs[['애니메이션ID', '선호도']])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "엔드포인트 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '51c5350c-6e30-46d8-929c-c5508680f10f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '51c5350c-6e30-46d8-929c-c5508680f10f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Wed, 14 Aug 2024 08:44:06 GMT',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = boto3_session.client('sagemaker')\n",
    "sm.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
